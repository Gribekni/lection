{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e1e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9edbc625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример первых 20 слов:\n",
      "лорен донер фьюри пролог вот дерьмо пробормотать элли себя под нос наблюдать за мужчина приковать к стена в соседний комната\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/roman/Downloads/Doner_Loren_Furi_(LP)_Litmir.net_bid224439_2a09f.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='cp1251') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "tokens = [\n",
    "    token.lemma_.lower()\n",
    "    for token in doc\n",
    "    if token.is_alpha and not token.is_space and not token.is_punct\n",
    "]\n",
    "\n",
    "print(\"Пример первых 20 слов:\")\n",
    "print(\" \".join(tokens[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03f583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Биграмм: 99,662\n",
      "Триграмм: 99,661\n"
     ]
    }
   ],
   "source": [
    "def make_ngrams(token_list, n):\n",
    "    return [tuple(token_list[i:i + n]) for i in range(len(token_list) - n + 1)]\n",
    "\n",
    "bigrams = make_ngrams(tokens, 2)\n",
    "trigrams = make_ngrams(tokens, 3)\n",
    "\n",
    "print(f\"Биграмм: {len(bigrams):,}\")\n",
    "print(f\"Триграмм: {len(trigrams):,}\")\n",
    "\n",
    "def build_ngram_model(ngram_list):\n",
    "    model = defaultdict(Counter)\n",
    "    for gram in ngram_list:\n",
    "        context = gram[:-1]\n",
    "        next_word = gram[-1]\n",
    "        model[context][next_word] += 1\n",
    "    return model\n",
    "\n",
    "bigram_model = build_ngram_model(bigrams)\n",
    "trigram_model = build_ngram_model(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10236354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После слова \"он\" чаще всего шли:\n",
      " - \"не\" — 121 раз\n",
      " - \"быть\" — 55 раз\n",
      " - \"хотеть\" — 44 раз\n",
      " - \"лицо\" — 41 раз\n",
      " - \"взгляд\" — 38 раз\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def build_ngram_model(ngram_list):\n",
    "    model = defaultdict(Counter)\n",
    "    \n",
    "    for gram in ngram_list:\n",
    "       \n",
    "        context = gram[:-1]\n",
    "        next_word = gram[-1]\n",
    "        model[context][next_word] += 1\n",
    "    \n",
    "    return model\n",
    "\n",
    "bigram_model = build_ngram_model(bigrams)\n",
    "trigram_model = build_ngram_model(trigrams)\n",
    "\n",
    "example = ('он',)\n",
    "print(f\"После слова \\\"{example[0]}\\\" чаще всего шли:\")\n",
    "for word, count in bigram_model[example].most_common(5):\n",
    "    print(f\" - \\\"{word}\\\" — {count} раз\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac82637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, n, length=10):\n",
    "    context = random.choice(list(model.keys()))\n",
    "    output = list(context)\n",
    "    \n",
    "    for _ in range(length):\n",
    "        if context not in model:\n",
    "            break\n",
    "        next_words = model[context]\n",
    "        \n",
    "        next_word = random.choices(\n",
    "            list(next_words.keys()),\n",
    "            weights=list(next_words.values())\n",
    "        )[0]\n",
    "        \n",
    "        output.append(next_word)\n",
    "        context = tuple(output[-(n - 1):])\n",
    "    \n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb59575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigrams:\n",
      "глянула на весь это не сжечь лифчик фьюри не сделать элли\n",
      "\n",
      "Trigrams:\n",
      "бриз оказаться достаточно доказательство чтобы судья наконец то оставить элли в лаборатория\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBigrams:\")\n",
    "print(generate_text(bigram_model, 2, length=10))\n",
    "print(\"\\nTrigrams:\")\n",
    "print(generate_text(trigram_model, 3, length=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5aed0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Сейчас позапускав пару раз, смог вывести два текста, первый исходя из биграмм, второй - из триграмм. И отчётливо видно, что в биграммах сгенерился будто бы текст из рандомных слов, оочень странный порядок, во втором же предожении прослеживается некий смысл, даже несмотря на то, что всё лемматизировано. Короче говоря, чем больше контекста знает модель, тем лучше. ЯВНО лучше, даже если контекст всего на одно слово больше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
