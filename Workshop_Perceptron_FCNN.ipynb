{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Практическое занятие: Персептрон и простая полносвязная нейросеть (NumPy + Pandas + Plotly)\n",
        "\n",
        "В этом блокноте мы шаг за шагом разберёмся с работой простого персептрона и небольшой полносвязной нейросети (1 скрытый слой), реализованными «с нуля» на NumPy. Будем использовать маленький датасет (≤5000 образцов) и визуализировать результаты с помощью Plotly.\n",
        "\n",
        "## Чек-лист урока\n",
        "- [x] Краткий ресерч небольших датасетов (≤5000 образцов)\n",
        "- [x] Загрузка небольшого реального датасета через Pandas\n",
        "- [x] EDA и базовая визуализация (Plotly)\n",
        "- [x] Персептрон: формулы, обучение, визуализация границы\n",
        "- [x] FCNN (1 скрытый слой): прямой ход, функции активации, потери, обратное распространение, обучение\n",
        "- [x] Оценка качества и выводы\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Небольшие датасеты: что выбрать для практики\n",
        "\n",
        "Ниже — небольшая подборка простых и широко используемых датасетов (все ≤5000 образцов), подходящих для занятия по персептрону/полносвязной НС. Ссылки на страницы и удобные CSV-источники:\n",
        "\n",
        "- Iris (150 объектов, 3 класса, 4 признака)\n",
        "  - Описание: `https://archive.ics.uci.edu/ml/datasets/iris`\n",
        "  - CSV (готовый с заголовками): `https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv`\n",
        "- Wine (178 объектов, 3 класса, 13 признаков)\n",
        "  - Описание: `https://archive.ics.uci.edu/ml/datasets/wine`\n",
        "  - RAW data (без заголовков): `https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data`\n",
        "- Breast Cancer Wisconsin Diagnostic (569 объектов, 2 класса)\n",
        "  - Описание: `https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)`\n",
        "  - RAW data (без заголовков): `https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data`\n",
        "- Pima Indians Diabetes (768 объектов, 2 класса)\n",
        "  - Описание: `https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes`\n",
        "  - CSV (с заголовками в community-версии): `https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv`\n",
        "- Banknote Authentication (1372 объекта, 2 класса, 4 признака)\n",
        "  - Описание: `https://archive.ics.uci.edu/ml/datasets/banknote+authentication`\n",
        "  - CSV: `https://raw.githubusercontent.com/jbrownlee/Datasets/master/banknote_authentication.csv`\n",
        "\n",
        "Дополнительно:\n",
        "- OpenML (каталог датасетов): `https://www.openml.org`\n",
        "- Наборы scikit-learn (описания): `https://scikit-learn.org/stable/datasets/toy_dataset.html`\n",
        "\n",
        "В этом практикуме мы используем Iris как основной пример: он очень маленький, чистый и понятный.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from typing import Tuple\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Небольшие утилиты\n",
        "\n",
        "def train_test_split_np(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, shuffle: bool = True, seed: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Простейший train/test split на NumPy без зависимостей.\"\"\"\n",
        "    assert 0 < test_size < 1\n",
        "    n_samples = X.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(indices)\n",
        "    test_count = int(n_samples * test_size)\n",
        "    test_idx = indices[:test_count]\n",
        "    train_idx = indices[test_count:]\n",
        "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
        "\n",
        "\n",
        "def zscore_fit_transform(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Стандартизация z-score: возвращает X_scaled, mean, std.\"\"\"\n",
        "    mean = X.mean(axis=0, keepdims=True)\n",
        "    std = X.std(axis=0, keepdims=True) + 1e-8\n",
        "    return (X - mean) / std, mean, std\n",
        "\n",
        "\n",
        "def zscore_transform(X: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    return (X - mean) / (std + 1e-8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загружаем датасет Iris и делаем краткий EDA\n",
        "\n",
        "Источник CSV: `https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv`\n",
        "\n",
        "Столбцы: `sepal_length`, `sepal_width`, `petal_length`, `petal_width`, `species`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "df = pd.read_csv(iris_url)\n",
        "print(df.head())\n",
        "print(\"\\nФорма:\", df.shape)\n",
        "print(\"\\nКлассы:\")\n",
        "print(df[\"species\"].value_counts())\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    df,\n",
        "    dimensions=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "    color=\"species\",\n",
        "    title=\"Iris: Scatter Matrix по признакам\"\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Персептрон: бинарная классификация двух видов Iris\n",
        "\n",
        "Для персептрона выберем два класса (например, `setosa` и `versicolor`) и два признака, чтобы можно было красиво визуализировать границу решения. Признаки: `sepal_length`, `petal_length`.\n",
        "\n",
        "Метки преобразуем в {-1, +1} для классического обновления весов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bin = df[df[\"species\"].isin([\"setosa\", \"versicolor\"])].copy()\n",
        "feat_cols = [\"sepal_length\", \"petal_length\"]\n",
        "X = df_bin[feat_cols].to_numpy(dtype=float)\n",
        "y = (df_bin[\"species\"].to_numpy() == \"versicolor\").astype(int)\n",
        "# Преобразуем метки в {-1, +1}\n",
        "y = np.where(y == 1, 1, -1)\n",
        "\n",
        "# Стандартизация только по train\n",
        "X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_size=0.2, shuffle=True, seed=42)\n",
        "X_train_scaled, m, s = zscore_fit_transform(X_train)\n",
        "X_test_scaled = zscore_transform(X_test, m, s)\n",
        "\n",
        "print(\"Размеры:\", X_train_scaled.shape, X_test_scaled.shape)\n",
        "\n",
        "fig = px.scatter(\n",
        "    x=X_train_scaled[:, 0], y=X_train_scaled[:, 1], color=y_train.astype(str),\n",
        "    labels={\"x\": feat_cols[0], \"y\": feat_cols[1]},\n",
        "    title=\"Train точки (стандартизованные)\"\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Теория: обновление весов персептрона\n",
        "\n",
        "- Активация: \\(\\hat{y} = \\operatorname{sign}(w^T x + b)\\)\n",
        "- Ошибка: \\(e = y - \\hat{y}\\)\n",
        "- Обновление параметров (перцептронное правило): \\(w \\leftarrow w + \\eta\\, e\\, x\\), \\(b \\leftarrow b + \\eta\\, e\\)\n",
        "\n",
        "Где \\(\\eta\\) — скорость обучения. Для бинарной классификации удобно \\(y \\in \\{-1, +1\\}\\).\n",
        "\n",
        "Ссылки:\n",
        "- Персептрон (RU): `https://ru.wikipedia.org/wiki/Персептрон`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learning_rate: float = 0.1, epochs: int = 50):\n",
        "        self.learning_rate = float(learning_rate)\n",
        "        self.epochs = int(epochs)\n",
        "        self.w = None  # shape: (n_features,)\n",
        "        self.b = 0.0\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.w = np.zeros(n_features, dtype=float)\n",
        "        self.b = 0.0\n",
        "        self.errors_per_epoch = []\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            errors = 0\n",
        "            for xi, yi in zip(X, y):\n",
        "                linear = np.dot(xi, self.w) + self.b\n",
        "                y_hat = 1 if linear >= 0 else -1\n",
        "                err = yi - y_hat\n",
        "                if err != 0:\n",
        "                    self.w += self.learning_rate * err * xi\n",
        "                    self.b += self.learning_rate * err\n",
        "                    errors += 1\n",
        "            self.errors_per_epoch.append(errors)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        linear = X @ self.w + self.b\n",
        "        return np.where(linear >= 0, 1, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "per_clf = Perceptron(learning_rate=0.1, epochs=50)\n",
        "per_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "fig = px.line(y=per_clf.errors_per_epoch, labels={\"x\": \"Эпоха\", \"y\": \"Ошибок за эпоху\"}, title=\"Сходимость персептрона\")\n",
        "fig.show()\n",
        "\n",
        "y_pred = per_clf.predict(X_test_scaled)\n",
        "acc = (y_pred == y_test).mean()\n",
        "print(f\"Точность (test): {acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация границы решения (2D)\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(X_train_scaled[:, 0].min()-0.5, X_train_scaled[:, 0].max()+0.5, 200),\n",
        "    np.linspace(X_train_scaled[:, 1].min()-0.5, X_train_scaled[:, 1].max()+0.5, 200)\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "zz = per_clf.predict(grid).reshape(xx.shape)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Contour(\n",
        "    x=xx[0], y=yy[:, 0], z=zz,\n",
        "    showscale=False, opacity=0.4, colorscale=[[0, '#A1D99B'], [1, '#9ECAE1']],\n",
        "    contours=dict(coloring='heatmap', showlabels=False)\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=X_train_scaled[:, 0], y=X_train_scaled[:, 1],\n",
        "    mode='markers',\n",
        "    marker=dict(color=y_train, colorscale=[[0, 'red'], [1, 'blue']]),\n",
        "    name='Train'\n",
        "))\n",
        "\n",
        "fig.update_layout(title='Персептрон: граница решения', xaxis_title=feat_cols[0], yaxis_title=feat_cols[1])\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Полносвязная нейросеть (1 скрытый слой) с нуля на NumPy\n",
        "\n",
        "Далее реализуем минимальную FCNN для многоклассовой классификации на Iris. Возьмём 2 признака — `petal_length`, `petal_width`, т.к. они хорошо разделяют классы визуально. Выход — 3 класса (softmax), функция потерь — кросс-энтропия.\n",
        "\n",
        "### Формулы (кратко)\n",
        "- Прямой ход:\n",
        "  - \\(Z_1 = X W_1 + b_1\\), \\(A_1 = \\phi(Z_1)\\) (возьмём ReLU)\n",
        "  - \\(Z_2 = A_1 W_2 + b_2\\), \\(\\hat{Y} = \\operatorname{softmax}(Z_2)\\)\n",
        "- Потери (кросс-энтропия): \\(L = -\\frac{1}{N} \\sum_i \\sum_k y_{ik} \\log(\\hat{y}_{ik})\\)\n",
        "- Обратное распространение:\n",
        "  - \\(\\nabla_{Z_2} = \\hat{Y} - Y\\)\n",
        "  - \\(\\nabla_{W_2} = A_1^T \\nabla_{Z_2} / N\\), \\(\\nabla_{b_2} = \\sum_i \\nabla_{Z_2}^{(i)} / N\\)\n",
        "  - \\(\\nabla_{A_1} = \\nabla_{Z_2} W_2^T\\), \\(\\nabla_{Z_1} = \\nabla_{A_1} \\odot \\phi'(Z_1)\\)\n",
        "  - \\(\\nabla_{W_1} = X^T \\nabla_{Z_1} / N\\), \\(\\nabla_{b_1} = \\sum_i \\nabla_{Z_1}^{(i)} / N\\)\n",
        "\n",
        "Ссылки:\n",
        "- Обратное распространение (RU): `https://ru.wikipedia.org/wiki/Обратное_распространение_ошибки`\n",
        "- CS231n Backprop: `https://cs231n.github.io/optimization-2/`\n",
        "- Michael Nielsen: `http://neuralnetworksanddeeplearning.com/chap1.html`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Готовим данные для многоклассовой задачи\n",
        "feat_mlp = [\"petal_length\", \"petal_width\"]\n",
        "X_full = df[feat_mlp].to_numpy(dtype=float)\n",
        "# Преобразуем species в 0/1/2\n",
        "label_to_id = {lbl: i for i, lbl in enumerate(sorted(df[\"species\"].unique()))}\n",
        "y_full = df[\"species\"].map(label_to_id).to_numpy(dtype=int)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split_np(X_full, y_full, test_size=0.2, shuffle=True, seed=42)\n",
        "X_train2_s, mean2, std2 = zscore_fit_transform(X_train2)\n",
        "X_test2_s = zscore_transform(X_test2, mean2, std2)\n",
        "\n",
        "num_classes = len(np.unique(y_full))\n",
        "print(\"Классов:\", num_classes, label_to_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функции активации и служебные функции\n",
        "\n",
        "def relu(x: np.ndarray) -> np.ndarray:\n",
        "    return np.maximum(0.0, x)\n",
        "\n",
        "def relu_grad(x: np.ndarray) -> np.ndarray:\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(z: np.ndarray) -> np.ndarray:\n",
        "    z_shift = z - z.max(axis=1, keepdims=True)\n",
        "    exp_z = np.exp(z_shift)\n",
        "    return exp_z / (exp_z.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def one_hot(y: np.ndarray, num_classes: int) -> np.ndarray:\n",
        "    oh = np.zeros((y.shape[0], num_classes), dtype=float)\n",
        "    oh[np.arange(y.shape[0]), y] = 1.0\n",
        "    return oh\n",
        "\n",
        "def cross_entropy(y_true_oh: np.ndarray, y_pred_proba: np.ndarray) -> float:\n",
        "    # средняя кросс-энтропия\n",
        "    return float(-np.mean(np.sum(y_true_oh * np.log(y_pred_proba + 1e-12), axis=1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    def __init__(self, in_features: int, hidden_units: int, out_classes: int, lr: float = 0.05, seed: int = 42):\n",
        "        self.in_features = int(in_features)\n",
        "        self.hidden_units = int(hidden_units)\n",
        "        self.out_classes = int(out_classes)\n",
        "        self.lr = float(lr)\n",
        "        rng = np.random.default_rng(seed)\n",
        "        # He init для ReLU\n",
        "        self.W1 = rng.normal(0.0, np.sqrt(2.0 / in_features), size=(in_features, hidden_units))\n",
        "        self.b1 = np.zeros((1, hidden_units), dtype=float)\n",
        "        self.W2 = rng.normal(0.0, np.sqrt(2.0 / hidden_units), size=(hidden_units, out_classes))\n",
        "        self.b2 = np.zeros((1, out_classes), dtype=float)\n",
        "\n",
        "    def forward(self, X: np.ndarray):\n",
        "        Z1 = X @ self.W1 + self.b1\n",
        "        A1 = relu(Z1)\n",
        "        Z2 = A1 @ self.W2 + self.b2\n",
        "        A2 = softmax(Z2)\n",
        "        cache = {\"X\": X, \"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
        "        return A2, cache\n",
        "\n",
        "    def backward(self, cache: dict, y_true: np.ndarray):\n",
        "        X, Z1, A1, A2 = cache[\"X\"], cache[\"Z1\"], cache[\"A1\"], cache[\"A2\"]\n",
        "        m = X.shape[0]\n",
        "        y_oh = one_hot(y_true, self.out_classes)\n",
        "        dZ2 = (A2 - y_oh) / m\n",
        "        dW2 = A1.T @ dZ2\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "        dA1 = dZ2 @ self.W2.T\n",
        "        dZ1 = dA1 * relu_grad(Z1)\n",
        "        dW1 = X.T @ dZ1\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "        grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "        return grads\n",
        "\n",
        "    def step(self, grads: dict):\n",
        "        self.W1 -= self.lr * grads[\"dW1\"]\n",
        "        self.b1 -= self.lr * grads[\"db1\"]\n",
        "        self.W2 -= self.lr * grads[\"dW2\"]\n",
        "        self.b2 -= self.lr * grads[\"db2\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Обучение MLP\n",
        "mlp = MLP(in_features=X_train2_s.shape[1], hidden_units=8, out_classes=num_classes, lr=0.05, seed=42)\n",
        "\n",
        "epochs = 300\n",
        "loss_hist = []\n",
        "acc_hist = []\n",
        "\n",
        "for ep in range(epochs):\n",
        "    probs, cache = mlp.forward(X_train2_s)\n",
        "    loss = cross_entropy(one_hot(y_train2, num_classes), probs)\n",
        "    grads = mlp.backward(cache, y_train2)\n",
        "    mlp.step(grads)\n",
        "\n",
        "    # метрики\n",
        "    y_pred_train = probs.argmax(axis=1)\n",
        "    acc_train = (y_pred_train == y_train2).mean()\n",
        "    loss_hist.append(loss)\n",
        "    acc_hist.append(acc_train)\n",
        "\n",
        "fig = px.line(y=loss_hist, labels={\"x\": \"Эпоха\", \"y\": \"Loss (CE)\"}, title=\"MLP: кросс-энтропия по эпохам\")\n",
        "fig.show()\n",
        "fig = px.line(y=acc_hist, labels={\"x\": \"Эпоха\", \"y\": \"Accuracy (train)\"}, title=\"MLP: Accuracy (train)\")\n",
        "fig.show()\n",
        "\n",
        "# Оценка на test\n",
        "probs_test, _ = mlp.forward(X_test2_s)\n",
        "y_pred_test = probs_test.argmax(axis=1)\n",
        "acc_test = (y_pred_test == y_test2).mean()\n",
        "print(f\"MLP точность (test): {acc_test:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Матрица ошибок и визуализация границы для 2D\n",
        "\n",
        "# Конфьюжен-матрица\n",
        "classes = [k for k, v in sorted(label_to_id.items(), key=lambda kv: kv[1])]\n",
        "cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "for yt, yp in zip(y_test2, y_pred_test):\n",
        "    cm[yt, yp] += 1\n",
        "\n",
        "fig = px.imshow(cm, text_auto=True, x=classes, y=classes, color_continuous_scale='Blues', title='Confusion matrix (test)')\n",
        "fig.update_xaxes(title_text='Предсказанный класс')\n",
        "fig.update_yaxes(title_text='Истинный класс')\n",
        "fig.show()\n",
        "\n",
        "# Визуализация границы решения для 2D признаков\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(X_train2_s[:, 0].min()-0.5, X_train2_s[:, 0].max()+0.5, 220),\n",
        "    np.linspace(X_train2_s[:, 1].min()-0.5, X_train2_s[:, 1].max()+0.5, 220)\n",
        ")\n",
        "\n",
        "grid2 = np.c_[xx.ravel(), yy.ravel()]\n",
        "probs_grid, _ = mlp.forward(grid2)\n",
        "zz = probs_grid.argmax(axis=1).reshape(xx.shape)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Contour(\n",
        "    x=xx[0], y=yy[:, 0], z=zz,\n",
        "    showscale=False, opacity=0.3,\n",
        "    contours=dict(coloring='heatmap')\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=X_train2_s[:, 0], y=X_train2_s[:, 1], mode='markers',\n",
        "    marker=dict(color=y_train2, colorscale='Viridis', line=dict(width=0.5, color='black')),\n",
        "    name='Train'\n",
        "))\n",
        "fig.update_layout(title='MLP: границы классов (2D)', xaxis_title=feat_mlp[0], yaxis_title=feat_mlp[1])\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выводы\n",
        "\n",
        "- Персептрон хорошо справляется с бинарной линейно-разделимой задачей; мы увидели его правило обучения и границу решения.\n",
        "- Простая FCNN (ReLU + Softmax) с кросс-энтропией и backprop способна решать многоклассовую классификацию на Iris, обучаясь на NumPy.\n",
        "- Важные практические моменты: стандартизация признаков, корректная инициализация весов (He для ReLU), контроль скорости обучения.\n",
        "\n",
        "## Полезные ссылки\n",
        "- Iris (описание): `https://archive.ics.uci.edu/ml/datasets/iris`\n",
        "- CSV Iris: `https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv`\n",
        "- Персептрон (RU): `https://ru.wikipedia.org/wiki/Персептрон`\n",
        "- Обратное распространение (RU): `https://ru.wikipedia.org/wiki/Обратное_распространение_ошибки`\n",
        "- CS231n Backprop: `https://cs231n.github.io/optimization-2/`\n",
        "- Michael Nielsen (гл.1): `http://neuralnetworksanddeeplearning.com/chap1.html`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
